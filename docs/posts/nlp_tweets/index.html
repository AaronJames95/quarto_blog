<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.42">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Aaron James">
<meta name="dcterms.date" content="2025-04-21">

<title>Predicting Disaster Tweets with NLP – Learning Learning</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-dark-b53751a350365c71b6c909e95f209ed1.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-cbb8612797ca2f5ea6d72598314dc22e.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>
<script src="https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js" crossorigin="anonymous"></script>


</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Learning Learning</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../index.html"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#nlp-kaggle-and-disaster-tweets" id="toc-nlp-kaggle-and-disaster-tweets" class="nav-link active" data-scroll-target="#nlp-kaggle-and-disaster-tweets">NLP, Kaggle, and Disaster Tweets</a></li>
  <li><a href="#downloading-the-dataset" id="toc-downloading-the-dataset" class="nav-link" data-scroll-target="#downloading-the-dataset">Downloading the dataset</a></li>
  <li><a href="#loading-the-data-and-eda" id="toc-loading-the-data-and-eda" class="nav-link" data-scroll-target="#loading-the-data-and-eda">Loading the data and EDA</a>
  <ul class="collapse">
  <li><a href="#analyzing-data-distributions" id="toc-analyzing-data-distributions" class="nav-link" data-scroll-target="#analyzing-data-distributions">Analyzing Data Distributions</a></li>
  <li><a href="#create-another-baseline" id="toc-create-another-baseline" class="nav-link" data-scroll-target="#create-another-baseline">Create another baseline</a></li>
  <li><a href="#defining-the-f1-metric" id="toc-defining-the-f1-metric" class="nav-link" data-scroll-target="#defining-the-f1-metric">Defining the F1 Metric</a></li>
  </ul></li>
  <li><a href="#iterating-from-the-baseline-results" id="toc-iterating-from-the-baseline-results" class="nav-link" data-scroll-target="#iterating-from-the-baseline-results">Iterating from the Baseline Results</a>
  <ul class="collapse">
  <li><a href="#analyzing-the-models-trouble-tweets-or-error-analysis" id="toc-analyzing-the-models-trouble-tweets-or-error-analysis" class="nav-link" data-scroll-target="#analyzing-the-models-trouble-tweets-or-error-analysis">Analyzing the Model’s “Trouble” Tweets (or Error Analysis)</a></li>
  <li><a href="#eda-on-baseline-results" id="toc-eda-on-baseline-results" class="nav-link" data-scroll-target="#eda-on-baseline-results">EDA on Baseline Results</a></li>
  </ul></li>
  <li><a href="#model-tweaking" id="toc-model-tweaking" class="nav-link" data-scroll-target="#model-tweaking">Model Tweaking</a>
  <ul class="collapse">
  <li><a href="#special-tokens" id="toc-special-tokens" class="nav-link" data-scroll-target="#special-tokens">Special Tokens?</a></li>
  </ul></li>
  <li><a href="#submitting-results" id="toc-submitting-results" class="nav-link" data-scroll-target="#submitting-results">Submitting Results</a></li>
  <li><a href="#reflection" id="toc-reflection" class="nav-link" data-scroll-target="#reflection">Reflection</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Predicting Disaster Tweets with NLP</h1>
  <div class="quarto-categories">
    <div class="quarto-category">machine learning</div>
    <div class="quarto-category">tutorial</div>
    <div class="quarto-category">fastai</div>
    <div class="quarto-category">NLP</div>
    <div class="quarto-category">kaggle</div>
  </div>
  </div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Aaron James </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">April 21, 2025</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<section id="nlp-kaggle-and-disaster-tweets" class="level1">
<h1>NLP, Kaggle, and Disaster Tweets</h1>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="nlp_tweets.png" class="img-fluid figure-img"></p>
<figcaption>nlp_tweets.png</figcaption>
</figure>
</div>
<p>This lesson focused on applying NLP using hugging face’s library. In the book we used the fastai library. I decided to apply what I learned to the <strong>kaggle <a href="https://www.kaggle.com/competitions/nlp-getting-started/overview">NLP disaster tweets competition</a></strong>. I’ll be referencing the two course notebooks for this lesson <a href="https://github.com/fastai/fastbook/blob/master/10_nlp.ipynb">Chapter 10</a> and <a href="https://www.kaggle.com/code/jhoward/getting-started-with-nlp-for-absolute-beginners">getting-started-with-NLP</a></p>
<p>The goal of this competition is to take a set of tweets and determine based on their metadata whether or not they refer to real disasters. We use Natural Language Processing (NLP) to fit a model to the tweets to make our predictions.</p>
<p>The first thing I did was make sure I could download the dataset.</p>
</section>
<section id="downloading-the-dataset" class="level1">
<h1>Downloading the dataset</h1>
<p>I wrote a short script to download the dataset. Actually, I just used the code from the getting-started notebook.</p>
<div id="b01baa81-8c90-4edc-b0c9-c90e0d8ed5af" class="cell" data-execution_count="1">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pathlib <span class="im">import</span> Path</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>iskaggle <span class="op">=</span> os.environ.get(<span class="st">'KAGGLE_KERNEL_RUN_TYPE'</span>, <span class="st">''</span>)</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>competition <span class="op">=</span> <span class="st">'nlp-getting-started'</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> iskaggle:</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>    <span class="op">!</span>pip install <span class="op">-</span>Uqq fastai</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>    <span class="im">import</span> zipfile,kaggle</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>    path <span class="op">=</span> Path(competition)</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>    kaggle.api.competition_download_cli(<span class="bu">str</span>(path))</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>    zipfile.ZipFile(<span class="ss">f'</span><span class="sc">{</span>path<span class="sc">}</span><span class="ss">.zip'</span>).extractall(path)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>nlp-getting-started.zip: Skipping, found more recently modified local copy (use --force to force download)</code></pre>
</div>
</div>
</section>
<section id="loading-the-data-and-eda" class="level1">
<h1>Loading the data and EDA</h1>
<p>Now that the dataset is downloaded, we want to load it into memory to start playing around with various features.</p>
<div id="115e4429-a642-425f-b131-a6af4d31e355" class="cell" data-execution_count="2">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># import relevant frameworks</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> fastai.imports <span class="im">import</span> <span class="op">*</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> iskaggle: path <span class="op">=</span> Path(<span class="st">'../input/'</span> <span class="op">+</span> competition)</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(path<span class="op">/</span><span class="st">'train.csv'</span>)</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>df_test <span class="op">=</span> pd.read_csv(path<span class="op">/</span><span class="st">'test.csv'</span>)</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>df.describe(include<span class="op">=</span><span class="st">'object'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="2">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">keyword</th>
<th data-quarto-table-cell-role="th">location</th>
<th data-quarto-table-cell-role="th">text</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">count</td>
<td>7552</td>
<td>5080</td>
<td>7613</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">unique</td>
<td>221</td>
<td>3341</td>
<td>7503</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">top</td>
<td>fatalities</td>
<td>USA</td>
<td>11-Year-Old Boy Charged With Manslaughter of Toddler: Report: An 11-year-old boy has been charged with manslaughter over the fatal sh...</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">freq</td>
<td>45</td>
<td>104</td>
<td>10</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<section id="analyzing-data-distributions" class="level2">
<h2 class="anchored" data-anchor-id="analyzing-data-distributions">Analyzing Data Distributions</h2>
<p>Since this is my first time looking at the dataset, I want to see what category breakdowns seem to be significant. Basically, I want to get a sense of what variables it might be helpful to look at more closely.</p>
<div id="0f96dff7-3c25-4d37-8e8a-26b19ce32cb5" class="cell" data-execution_count="3">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>df.keyword.value_counts()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="3">
<pre><code>keyword
fatalities               45
deluge                   42
armageddon               42
sinking                  41
damage                   41
                         ..
forest%20fire            19
epicentre                12
threat                   11
inundation               10
radiation%20emergency     9
Name: count, Length: 221, dtype: int64</code></pre>
</div>
</div>
<div id="a8d80940-2bb7-4fb1-9143-ae7dd38f34d2" class="cell" data-execution_count="4">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>df.location.value_counts()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="4">
<pre><code>location
USA                    104
New York                71
United States           50
London                  45
Canada                  29
                      ... 
MontrÌ©al, QuÌ©bec       1
Montreal                 1
ÌÏT: 6.4682,3.18287      1
Live4Heed??              1
Lincoln                  1
Name: count, Length: 3341, dtype: int64</code></pre>
</div>
</div>
</section>
<section id="create-another-baseline" class="level2">
<h2 class="anchored" data-anchor-id="create-another-baseline">Create another baseline</h2>
<p>I spent a good amount of time looking into novel ways to break the data down to give the model an optimal input. I considered:</p>
<ul>
<li>removing the <code>%20</code> and replacing with a space for the keywords</li>
<li>removing the location to see what impact that has</li>
<li>collapsing duplicate locations into one (theoretically, USA == United States)</li>
</ul>
<p>Then I realized, before I can determine how those edits would affect my results… I need results. I was reminded that for our last lesson we started by creating a baseline. I decided to do this in the simplest way I could think of and iterate from there. To me, that was squishing all the default features of the data into a single string, and training the model on that input.</p>
<div id="3f2f6160-7bea-4278-ba2c-5bf6d3f9479d" class="cell" data-execution_count="5">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>input_col <span class="op">=</span> <span class="st">'inputs'</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>na_fill <span class="op">=</span> <span class="st">''</span></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>df[input_col] <span class="op">=</span> <span class="st">'LOC: '</span> <span class="op">+</span> df.location.fillna(na_fill) <span class="op">+</span> <span class="st">'; KW: '</span> <span class="op">+</span> df.keyword.fillna(na_fill) <span class="op">+</span> <span class="st">'; TEXT: '</span> <span class="op">+</span> df.text.fillna(na_fill)</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>df.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="5">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">id</th>
<th data-quarto-table-cell-role="th">keyword</th>
<th data-quarto-table-cell-role="th">location</th>
<th data-quarto-table-cell-role="th">text</th>
<th data-quarto-table-cell-role="th">target</th>
<th data-quarto-table-cell-role="th">inputs</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>1</td>
<td>NaN</td>
<td>NaN</td>
<td>Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all</td>
<td>1</td>
<td>LOC: ; KW: ; TEXT: Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>4</td>
<td>NaN</td>
<td>NaN</td>
<td>Forest fire near La Ronge Sask. Canada</td>
<td>1</td>
<td>LOC: ; KW: ; TEXT: Forest fire near La Ronge Sask. Canada</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>5</td>
<td>NaN</td>
<td>NaN</td>
<td>All residents asked to 'shelter in place' are being notified by officers. No other evacuation or shelter in place orders are expected</td>
<td>1</td>
<td>LOC: ; KW: ; TEXT: All residents asked to 'shelter in place' are being notified by officers. No other evacuation or shelter in place orders are expected</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>6</td>
<td>NaN</td>
<td>NaN</td>
<td>13,000 people receive #wildfires evacuation orders in California</td>
<td>1</td>
<td>LOC: ; KW: ; TEXT: 13,000 people receive #wildfires evacuation orders in California</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>7</td>
<td>NaN</td>
<td>NaN</td>
<td>Just got sent this photo from Ruby #Alaska as smoke from #wildfires pours into a school</td>
<td>1</td>
<td>LOC: ; KW: ; TEXT: Just got sent this photo from Ruby #Alaska as smoke from #wildfires pours into a school</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div id="7190b13c-4ce3-4549-99b4-db8a9dc895c9" class="cell" data-execution_count="6">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Suppress warnings to make the output look cleaner</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers.utils <span class="im">import</span> logging</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> warnings</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>warnings.filterwarnings(<span class="st">"ignore"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div id="7af9583c-e6d2-497f-9481-cafc3e7d3354" class="cell" data-execution_count="7">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> datasets <span class="im">import</span> Dataset,DatasetDict</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> AutoModelForSequenceClassification,AutoTokenizer</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a><span class="co"># convert dataframe into a huggingface dataset</span></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>ds <span class="op">=</span> Dataset.from_pandas(df)</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>model_nm <span class="op">=</span> <span class="st">'microsoft/deberta-v3-small'</span></span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>tokz <span class="op">=</span> AutoTokenizer.from_pretrained(model_nm)</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> tok_func(x): <span class="cf">return</span> tokz(x[input_col])</span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a><span class="co"># tokenize the input</span></span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a>tok_ds <span class="op">=</span> ds.<span class="bu">map</span>(tok_func, batched<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a>tok_ds <span class="op">=</span> tok_ds.rename_columns({<span class="st">'target'</span>:<span class="st">'labels'</span>})</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stderr">
<pre><code>Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"09bbc009752548a0a7fa34b039f70ba1","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
</div>
<p>I briefly considered trying to engineer a perfect validation dataset before remembering that the goal was to create a simple baseline first</p>
<div id="ae9da523-e9bb-4dc9-823e-b567fd4d2aac" class="cell" data-execution_count="8">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Splitting up the validation set now</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>dds <span class="op">=</span> tok_ds.train_test_split(<span class="fl">0.25</span>, seed<span class="op">=</span><span class="dv">1337</span>)</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>dds</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="8">
<pre><code>DatasetDict({
    train: Dataset({
        features: ['id', 'keyword', 'location', 'text', 'labels', 'inputs', 'input_ids', 'token_type_ids', 'attention_mask'],
        num_rows: 5709
    })
    test: Dataset({
        features: ['id', 'keyword', 'location', 'text', 'labels', 'inputs', 'input_ids', 'token_type_ids', 'attention_mask'],
        num_rows: 1904
    })
})</code></pre>
</div>
</div>
</section>
<section id="defining-the-f1-metric" class="level2">
<h2 class="anchored" data-anchor-id="defining-the-f1-metric">Defining the F1 Metric</h2>
<p>The kaggle competition uses the <a href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html">F1 metric</a> between the predicted values and expected values. So we have to define it in a way that huggingface understands to use it in our training.</p>
<div id="a94203df-40d2-4dd8-9056-95fa3ce26dd5" class="cell" data-execution_count="9">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> f1_score, accuracy_score, precision_score, recall_score</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> compute_metrics(eval_pred):</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>    logits, labels <span class="op">=</span> eval_pred</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>    preds <span class="op">=</span> np.argmax(logits, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> {</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>        <span class="st">"f1"</span>: f1_score(labels, preds),</span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>        <span class="st">"accuracy"</span>: accuracy_score(labels, preds),</span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a>        <span class="st">"precision"</span>: precision_score(labels, preds),</span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>        <span class="st">"recall"</span>: recall_score(labels, preds)</span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a>df_eval <span class="op">=</span> dds[<span class="st">'test'</span>]</span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a>df_eval</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="9">
<pre><code>Dataset({
    features: ['id', 'keyword', 'location', 'text', 'labels', 'inputs', 'input_ids', 'token_type_ids', 'attention_mask'],
    num_rows: 1904
})</code></pre>
</div>
</div>
<p>Now we can run our training loop. I’m not deeply concerned with every hyper parameter here, because I’m not there yet. I just want to focus on epochs, batch size <code>bs</code> and learning rate <code>lr</code>.</p>
<div id="a5048e55-4142-4329-9ab5-b56a24de2ffe" class="cell" data-execution_count="10">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> TrainingArguments,Trainer</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>epochs <span class="op">=</span> <span class="dv">4</span></span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>bs <span class="op">=</span> <span class="dv">128</span></span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>lr <span class="op">=</span> <span class="fl">8e-5</span></span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a>args <span class="op">=</span> TrainingArguments(<span class="st">'outputs'</span>, learning_rate<span class="op">=</span>lr, warmup_ratio<span class="op">=</span><span class="fl">0.1</span>, lr_scheduler_type<span class="op">=</span><span class="st">'cosine'</span>, fp16<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a>    evaluation_strategy<span class="op">=</span><span class="st">"epoch"</span>, per_device_train_batch_size<span class="op">=</span>bs, per_device_eval_batch_size<span class="op">=</span>bs<span class="op">*</span><span class="dv">2</span>,</span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a>    num_train_epochs<span class="op">=</span>epochs, weight_decay<span class="op">=</span><span class="fl">0.01</span>, report_to<span class="op">=</span><span class="st">'none'</span>)</span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> AutoModelForSequenceClassification.from_pretrained(model_nm, num_labels<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a>trainer <span class="op">=</span> Trainer(model, args, train_dataset<span class="op">=</span>dds[<span class="st">'train'</span>], eval_dataset<span class="op">=</span>dds[<span class="st">'test'</span>],</span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a>                  tokenizer<span class="op">=</span>tokz, compute_metrics<span class="op">=</span>compute_metrics)</span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a>trainer.train()<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stderr">
<pre><code>Some weights of the model checkpoint at microsoft/deberta-v3-small were not used when initializing DebertaV2ForSequenceClassification: ['mask_predictions.LayerNorm.weight', 'mask_predictions.LayerNorm.bias', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.classifier.bias', 'mask_predictions.dense.bias', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.bias']
- This IS expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-small and are newly initialized: ['pooler.dense.weight', 'classifier.weight', 'pooler.dense.bias', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
You're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.</code></pre>
</div>
<div class="cell-output cell-output-display">

    <div>
      
      <progress value="180" max="180" style="width:300px; height:20px; vertical-align: middle;"></progress>
      [180/180 00:27, Epoch 4/4]
    </div>
    
<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">Epoch</th>
<th data-quarto-table-cell-role="th">Training Loss</th>
<th data-quarto-table-cell-role="th">Validation Loss</th>
<th data-quarto-table-cell-role="th">F1</th>
<th data-quarto-table-cell-role="th">Accuracy</th>
<th data-quarto-table-cell-role="th">Precision</th>
<th data-quarto-table-cell-role="th">Recall</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td>No log</td>
<td>0.524064</td>
<td>0.628931</td>
<td>0.752101</td>
<td>0.950119</td>
<td>0.470035</td>
</tr>
<tr class="even">
<td>2</td>
<td>No log</td>
<td>0.456287</td>
<td>0.751911</td>
<td>0.812500</td>
<td>0.920068</td>
<td>0.635723</td>
</tr>
<tr class="odd">
<td>3</td>
<td>No log</td>
<td>0.462908</td>
<td>0.783172</td>
<td>0.824055</td>
<td>0.871758</td>
<td>0.710928</td>
</tr>
<tr class="even">
<td>4</td>
<td>No log</td>
<td>0.476750</td>
<td>0.787008</td>
<td>0.820903</td>
<td>0.840000</td>
<td>0.740306</td>
</tr>
</tbody>
</table>
<p>
</p></div>
</div>
</section>
</section>
<section id="iterating-from-the-baseline-results" class="level1">
<h1>Iterating from the Baseline Results</h1>
<p>Alright ok thank God. It took a while, but we got a baseline. I tried a few randoms seeds for the test split. I got F1 values of .7949, .7948, and .8049. This is good because it tells me that based on a few random splits the metric doesn’t change too much. Now we want to see what are the hardest tweets to classify. We started with the baseline to just give us a sense of what data gives the model trouble. We didn’t curate a validation set, because we were stumped on which aspects of the data to sort into a valdiation set. Analyzing the tweets that are hardest to classify hopefully gives us a sense of what data features lead to trouble for the model.</p>
<section id="analyzing-the-models-trouble-tweets-or-error-analysis" class="level2">
<h2 class="anchored" data-anchor-id="analyzing-the-models-trouble-tweets-or-error-analysis">Analyzing the Model’s “Trouble” Tweets (or Error Analysis)</h2>
<p>First I’ll store the main outputs of the training for further analysis</p>
<div id="3a126688-a0ce-463b-95e6-426b965968cd" class="cell" data-execution_count="11">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn.functional <span class="im">as</span> F</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> fastai.vision.<span class="bu">all</span> <span class="im">import</span> <span class="op">*</span></span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a><span class="co"># save our validation set under a new name</span></span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>df_eval <span class="op">=</span> dds[<span class="st">'test'</span>]</span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Get predictions and probabilities</span></span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a>outputs <span class="op">=</span> trainer.predict(df_eval)</span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a>logits <span class="op">=</span> outputs.predictions</span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a>labels <span class="op">=</span> outputs.label_ids</span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a>probs <span class="op">=</span> F.softmax(tensor(logits), dim<span class="op">=</span><span class="dv">1</span>).numpy()</span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a>preds <span class="op">=</span> probs.argmax(axis<span class="op">=</span><span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">

</div>
</div>
<p>Now I want to create a dataframe that has additional relevant features. We already have the training output, so these new features will be based on the training. Once I have this dataframe I can start visualizing it in different ways</p>
<div id="2a7fbd97-0138-46d6-a88e-eb129ecde95c" class="cell" data-execution_count="12">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute per-example loss</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>losses <span class="op">=</span> [F.cross_entropy(tensor(logit), tensor(preds)) <span class="cf">for</span> logit, preds <span class="kw">in</span> <span class="bu">zip</span>(logits, preds)]</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> count_cap(text):</span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>    words <span class="op">=</span> text.split()</span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>    count <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> word <span class="kw">in</span> words:</span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> word <span class="kw">and</span> word[<span class="dv">0</span>].isupper():</span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a>            count <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> count</span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Set up up new dataframe with the results of the first pass</span></span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a>df_valid_results <span class="op">=</span> pd.DataFrame({</span>
<span id="cb19-14"><a href="#cb19-14" aria-hidden="true" tabindex="-1"></a>    <span class="st">"text"</span>: [df_eval[i][<span class="st">"text"</span>] <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(df_eval))],</span>
<span id="cb19-15"><a href="#cb19-15" aria-hidden="true" tabindex="-1"></a>    <span class="st">"keyword"</span>: [df_eval[i].get(<span class="st">"keyword"</span>) <span class="kw">or</span> <span class="st">"n/a"</span> <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(labels))],</span>
<span id="cb19-16"><a href="#cb19-16" aria-hidden="true" tabindex="-1"></a>    <span class="st">"location"</span>: [df_eval[i].get(<span class="st">"location"</span>) <span class="kw">or</span> <span class="st">"n/a"</span> <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(labels))],</span>
<span id="cb19-17"><a href="#cb19-17" aria-hidden="true" tabindex="-1"></a>    <span class="st">"label"</span>: labels,</span>
<span id="cb19-18"><a href="#cb19-18" aria-hidden="true" tabindex="-1"></a>    <span class="st">"cap_ratio"</span>: [count_cap(twt)<span class="op">/</span><span class="bu">float</span>(<span class="bu">len</span>(twt)) <span class="cf">for</span> twt <span class="kw">in</span> df_eval[<span class="st">'text'</span>]],</span>
<span id="cb19-19"><a href="#cb19-19" aria-hidden="true" tabindex="-1"></a>    <span class="st">"pred"</span>: preds,</span>
<span id="cb19-20"><a href="#cb19-20" aria-hidden="true" tabindex="-1"></a>    <span class="st">"prob_1"</span>: probs[:, <span class="dv">1</span>],</span>
<span id="cb19-21"><a href="#cb19-21" aria-hidden="true" tabindex="-1"></a>    <span class="st">"contains_link"</span>: [twt.count(<span class="st">"http"</span>) <span class="op">&gt;</span> <span class="dv">0</span> <span class="cf">for</span> twt <span class="kw">in</span> df_eval[<span class="st">'text'</span>]],</span>
<span id="cb19-22"><a href="#cb19-22" aria-hidden="true" tabindex="-1"></a>    <span class="st">"tweet_len"</span>: [<span class="bu">len</span>(twt) <span class="cf">for</span> twt <span class="kw">in</span> df_eval[<span class="st">'text'</span>]],</span>
<span id="cb19-23"><a href="#cb19-23" aria-hidden="true" tabindex="-1"></a>    <span class="st">"hashtags"</span>: [twt.count(<span class="st">"#"</span>) <span class="cf">for</span> twt <span class="kw">in</span> df_eval[<span class="st">'text'</span>]],</span>
<span id="cb19-24"><a href="#cb19-24" aria-hidden="true" tabindex="-1"></a>    <span class="st">"is_location"</span>: [<span class="bu">bool</span>(loc) <span class="cf">for</span> loc <span class="kw">in</span> df_eval[<span class="st">'location'</span>]],</span>
<span id="cb19-25"><a href="#cb19-25" aria-hidden="true" tabindex="-1"></a>    <span class="st">"loss"</span>: losses</span>
<span id="cb19-26"><a href="#cb19-26" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb19-27"><a href="#cb19-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-28"><a href="#cb19-28" aria-hidden="true" tabindex="-1"></a><span class="co"># Tag confusion type</span></span>
<span id="cb19-29"><a href="#cb19-29" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> label_type(row):</span>
<span id="cb19-30"><a href="#cb19-30" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> row.label <span class="op">==</span> <span class="dv">1</span> <span class="kw">and</span> row.pred <span class="op">==</span> <span class="dv">1</span>: <span class="cf">return</span> <span class="st">"TP"</span></span>
<span id="cb19-31"><a href="#cb19-31" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> row.label <span class="op">==</span> <span class="dv">0</span> <span class="kw">and</span> row.pred <span class="op">==</span> <span class="dv">0</span>: <span class="cf">return</span> <span class="st">"TN"</span></span>
<span id="cb19-32"><a href="#cb19-32" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> row.label <span class="op">==</span> <span class="dv">1</span> <span class="kw">and</span> row.pred <span class="op">==</span> <span class="dv">0</span>: <span class="cf">return</span> <span class="st">"FN"</span></span>
<span id="cb19-33"><a href="#cb19-33" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>: <span class="cf">return</span> <span class="st">"FP"</span></span>
<span id="cb19-34"><a href="#cb19-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-35"><a href="#cb19-35" aria-hidden="true" tabindex="-1"></a>df_valid_results[<span class="st">"type"</span>] <span class="op">=</span> df_valid_results.<span class="bu">apply</span>(label_type, axis<span class="op">=</span><span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="eda-on-baseline-results" class="level2">
<h2 class="anchored" data-anchor-id="eda-on-baseline-results">EDA on Baseline Results</h2>
<p>You can see from the creation of this dataset some of my ideas on relevant features. Frankly I spent too much time going down the feature engineering rabbit hole. The whole point of our baseline is that we can see what are the tweets that the model find hardest to classify. Theoretically this will give us some insight on how to structure a more optimal input string.</p>
<p>The first method I tried was to sort each tweet by the cross-entropy loss function.</p>
<div id="030826f0-6992-425f-a2da-67799e626d3b" class="cell" data-execution_count="13">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>df_valid_results.sort_values(by<span class="op">=</span><span class="st">"loss"</span>, ascending<span class="op">=</span><span class="va">False</span>).head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="13">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">text</th>
<th data-quarto-table-cell-role="th">keyword</th>
<th data-quarto-table-cell-role="th">location</th>
<th data-quarto-table-cell-role="th">label</th>
<th data-quarto-table-cell-role="th">cap_ratio</th>
<th data-quarto-table-cell-role="th">pred</th>
<th data-quarto-table-cell-role="th">prob_1</th>
<th data-quarto-table-cell-role="th">contains_link</th>
<th data-quarto-table-cell-role="th">tweet_len</th>
<th data-quarto-table-cell-role="th">hashtags</th>
<th data-quarto-table-cell-role="th">is_location</th>
<th data-quarto-table-cell-role="th">loss</th>
<th data-quarto-table-cell-role="th">type</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">264</td>
<td>'Since1970the 2 biggest depreciations in CAD:USD in yr b4federal election coincide w/landslide win for opposition' http://t.co/wgqKXmby3B</td>
<td>landslide</td>
<td>n/a</td>
<td>0</td>
<td>0.007299</td>
<td>1</td>
<td>0.500412</td>
<td>True</td>
<td>137</td>
<td>0</td>
<td>False</td>
<td>tensor(0.6923)</td>
<td>FP</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1831</td>
<td>Firepower in the lab [electronic resource] : automation in the fight against infectious diseases and bioterrorism /‰Û_ http://t.co/KvpbybglSR</td>
<td>bioterrorism</td>
<td>n/a</td>
<td>0</td>
<td>0.007092</td>
<td>1</td>
<td>0.501099</td>
<td>True</td>
<td>141</td>
<td>0</td>
<td>False</td>
<td>tensor(0.6910)</td>
<td>FP</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">654</td>
<td>@JakeGint the mass murder got her hot and bothered but at heart she was always a traditionalist.</td>
<td>mass%20murder</td>
<td>n/a</td>
<td>1</td>
<td>0.000000</td>
<td>0</td>
<td>0.498703</td>
<td>False</td>
<td>96</td>
<td>0</td>
<td>False</td>
<td>tensor(0.6906)</td>
<td>FN</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">399</td>
<td>Of what use exactly is the national Assembly? Honestly they are worthless. We are derailed.</td>
<td>derailed</td>
<td>Kwara, Nigeria</td>
<td>0</td>
<td>0.043956</td>
<td>0</td>
<td>0.496643</td>
<td>False</td>
<td>91</td>
<td>0</td>
<td>True</td>
<td>tensor(0.6865)</td>
<td>TN</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">960</td>
<td>Hat #russian soviet army kgb military #cossack #ushanka LINK:\nhttp://t.co/bla42Rdt1O http://t.co/EInSQS8tFq</td>
<td>military</td>
<td>n/a</td>
<td>0</td>
<td>0.018349</td>
<td>1</td>
<td>0.503387</td>
<td>True</td>
<td>109</td>
<td>3</td>
<td>False</td>
<td>tensor(0.6864)</td>
<td>FP</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>I can immediately see a problem with this. We don’t only get incorrect predictions! Indeed the highest loss value across our entire dataset was a correct prediction. This means, we have to sort our data by different values to determine which tweets caused the most trouble. My strategy was to sort by a new “confidence” feature, and only look at the data that was predicted incorrectly.</p>
<div id="9aae8452-a620-4065-8239-2813925ba060" class="cell" data-execution_count="14">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>df_valid_results[<span class="st">"prob_0"</span>] <span class="op">=</span> <span class="dv">1</span> <span class="op">-</span> df_valid_results[<span class="st">"prob_1"</span>]</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>df_valid_results[<span class="st">"is_wrong"</span>] <span class="op">=</span> (df_valid_results[<span class="st">"label"</span>] <span class="op">!=</span> df_valid_results[<span class="st">"pred"</span>])</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>df_valid_results[<span class="st">"confidence"</span>] <span class="op">=</span> df_valid_results[[<span class="st">"prob_1"</span>, <span class="st">"prob_0"</span>]].<span class="bu">max</span>(axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a>conf_sorted <span class="op">=</span> df_valid_results.sort_values(by<span class="op">=</span><span class="st">"confidence"</span>, ascending<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a>filtered <span class="op">=</span> conf_sorted[conf_sorted[<span class="st">"is_wrong"</span>] <span class="op">==</span> <span class="va">True</span>]</span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a>filtered.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="14">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">text</th>
<th data-quarto-table-cell-role="th">keyword</th>
<th data-quarto-table-cell-role="th">location</th>
<th data-quarto-table-cell-role="th">label</th>
<th data-quarto-table-cell-role="th">cap_ratio</th>
<th data-quarto-table-cell-role="th">pred</th>
<th data-quarto-table-cell-role="th">prob_1</th>
<th data-quarto-table-cell-role="th">contains_link</th>
<th data-quarto-table-cell-role="th">tweet_len</th>
<th data-quarto-table-cell-role="th">hashtags</th>
<th data-quarto-table-cell-role="th">is_location</th>
<th data-quarto-table-cell-role="th">loss</th>
<th data-quarto-table-cell-role="th">type</th>
<th data-quarto-table-cell-role="th">prob_0</th>
<th data-quarto-table-cell-role="th">is_wrong</th>
<th data-quarto-table-cell-role="th">confidence</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">770</td>
<td>Over half of poll respondents worry nuclear disaster fading from public consciousness http://t.co/YtnnnD631z ##fukushima</td>
<td>nuclear%20disaster</td>
<td>Fukushima city Fukushima.pref</td>
<td>0</td>
<td>0.008333</td>
<td>1</td>
<td>0.998309</td>
<td>True</td>
<td>120</td>
<td>2</td>
<td>True</td>
<td>tensor(0.0017)</td>
<td>FP</td>
<td>0.001691</td>
<td>True</td>
<td>0.998309</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1877</td>
<td>Angry Woman Openly Accuses NEMA Of Stealing Relief Materials Meant For IDPs: An angry Internally Displaced wom... http://t.co/6ySbCSSzYS</td>
<td>displaced</td>
<td>Nigeria</td>
<td>0</td>
<td>0.110294</td>
<td>1</td>
<td>0.998276</td>
<td>True</td>
<td>136</td>
<td>0</td>
<td>True</td>
<td>tensor(0.0017)</td>
<td>FP</td>
<td>0.001724</td>
<td>True</td>
<td>0.998276</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">305</td>
<td>#hot C-130 specially modified to land in a stadium and rescue hostages in Iran in 1980 http://t.co/zY3hpdJNwg #prebreak #best</td>
<td>hostages</td>
<td>china</td>
<td>0</td>
<td>0.015873</td>
<td>1</td>
<td>0.998269</td>
<td>True</td>
<td>126</td>
<td>3</td>
<td>True</td>
<td>tensor(0.0017)</td>
<td>FP</td>
<td>0.001731</td>
<td>True</td>
<td>0.998269</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">89</td>
<td>Satellite Spies Super Typhoon Soudelor from Space (Photo) http://t.co/VBhu2t8wgB</td>
<td>typhoon</td>
<td>Evergreen Colorado</td>
<td>0</td>
<td>0.075000</td>
<td>1</td>
<td>0.998245</td>
<td>True</td>
<td>80</td>
<td>0</td>
<td>True</td>
<td>tensor(0.0018)</td>
<td>FP</td>
<td>0.001755</td>
<td>True</td>
<td>0.998245</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">378</td>
<td>Angry Woman Openly Accuses NEMA Of Stealing Relief Materials Meant For IDPs: An angry Internally Displaced wom... http://t.co/Khd99oZ7u3</td>
<td>displaced</td>
<td>Ojodu,Lagos</td>
<td>0</td>
<td>0.110294</td>
<td>1</td>
<td>0.998168</td>
<td>True</td>
<td>136</td>
<td>0</td>
<td>True</td>
<td>tensor(0.0018)</td>
<td>FP</td>
<td>0.001832</td>
<td>True</td>
<td>0.998168</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>These are the tweets that the model was most confident about that it got wrong. Unfortunately, I never really was able to extract more meaningful data from the dataset. When I compare features like keyword, location, has_link, or hashtags, there just isn’t much difference between the wrong predictions and the full dataset.</p>
<div id="4f54a2ae-1c69-4f34-99fe-d65d180ecee7" class="cell" data-execution_count="15">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> compare_preds(feature):</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>    full_set_data, wrongs_only_data <span class="op">=</span> conf_sorted, filtered</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>    max_total_perc <span class="op">=</span> full_set_data[feature].value_counts().<span class="bu">max</span>()<span class="op">/</span><span class="bu">len</span>(conf_sorted)</span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a>    max_wrong_perc <span class="op">=</span> wrongs_only_data[feature].value_counts().<span class="bu">max</span>()<span class="op">/</span><span class="bu">len</span>(filtered)</span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(feature, max_total_perc, max_wrong_perc)</span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a>compare_preds(<span class="st">'keyword'</span>)</span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a>compare_preds(<span class="st">'location'</span>)</span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true" tabindex="-1"></a>compare_preds(<span class="st">'contains_link'</span>)</span>
<span id="cb22-11"><a href="#cb22-11" aria-hidden="true" tabindex="-1"></a>compare_preds(<span class="st">'hashtags'</span>)</span>
<span id="cb22-12"><a href="#cb22-12" aria-hidden="true" tabindex="-1"></a>filtered[<span class="st">'keyword'</span>].value_counts()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>keyword 0.007878151260504201 0.017595307917888565
location 0.3382352941176471 0.31671554252199413
contains_link 0.5341386554621849 0.5043988269794721
hashtags 0.7657563025210085 0.7771260997067448</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="15">
<pre><code>keyword
bioterror              6
hellfire               5
pandemonium            5
burning%20buildings    4
fire                   4
                      ..
sirens                 1
wild%20fires           1
bombed                 1
injured                1
landslide              1
Name: count, Length: 168, dtype: int64</code></pre>
</div>
</div>
<p>We see that the keywords values is significantly different in the incorrect portion of the dataset. But again, the only meaningful way to split this would be to break up each of these problem keywords into a train/valid proportion. We would hope that the model would generalize for the first few keywords and be able to predict the others two but that doesn’t seem likely. Unfortunately, it seems like the bins for each keyword are too small for the model to make meaningful generalizations.</p>
</section>
</section>
<section id="model-tweaking" class="level1">
<h1>Model Tweaking</h1>
<p>I think I just want to try some small tweaks now to see if we can optimize the results. I thought about using another model to get sentiment analysis for the tweets, but I’m not sure if I want to do that right now.</p>
<div id="670c216d-ee9c-44ed-a19b-82f4a05b3beb" class="cell" data-execution_count="16">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Some functions that expedite turning new inputs into training data</span></span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>epochs <span class="op">=</span> <span class="dv">4</span></span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>bs <span class="op">=</span> <span class="dv">128</span></span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>lr <span class="op">=</span> <span class="fl">8e-5</span></span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a>wd <span class="op">=</span> <span class="fl">0.01</span></span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_dds(df):</span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a>    inps <span class="op">=</span> <span class="st">"location"</span>, <span class="st">"keyword"</span>, <span class="st">"text"</span></span>
<span id="cb25-9"><a href="#cb25-9" aria-hidden="true" tabindex="-1"></a>    ds <span class="op">=</span> Dataset.from_pandas(df).rename_column(<span class="st">'target'</span>, <span class="st">'label'</span>)</span>
<span id="cb25-10"><a href="#cb25-10" aria-hidden="true" tabindex="-1"></a>    tok_ds <span class="op">=</span> ds.<span class="bu">map</span>(tok_func, batched<span class="op">=</span><span class="va">True</span>, remove_columns<span class="op">=</span>inps)</span>
<span id="cb25-11"><a href="#cb25-11" aria-hidden="true" tabindex="-1"></a>    dds <span class="op">=</span> tok_ds.train_test_split(<span class="fl">0.25</span>, seed<span class="op">=</span><span class="dv">52</span>)</span>
<span id="cb25-12"><a href="#cb25-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> dds</span>
<span id="cb25-13"><a href="#cb25-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-14"><a href="#cb25-14" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_model(): <span class="cf">return</span> AutoModelForSequenceClassification.from_pretrained(model_nm, num_labels<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb25-15"><a href="#cb25-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-16"><a href="#cb25-16" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_trainer(dds, model<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb25-17"><a href="#cb25-17" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> model <span class="kw">is</span> <span class="va">None</span>: model <span class="op">=</span> get_model()</span>
<span id="cb25-18"><a href="#cb25-18" aria-hidden="true" tabindex="-1"></a>    args <span class="op">=</span> TrainingArguments(<span class="st">'outputs'</span>, learning_rate<span class="op">=</span>lr, warmup_ratio<span class="op">=</span><span class="fl">0.1</span>, lr_scheduler_type<span class="op">=</span><span class="st">'cosine'</span>, fp16<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb25-19"><a href="#cb25-19" aria-hidden="true" tabindex="-1"></a>        evaluation_strategy<span class="op">=</span><span class="st">"epoch"</span>, per_device_train_batch_size<span class="op">=</span>bs, per_device_eval_batch_size<span class="op">=</span>bs<span class="op">*</span><span class="dv">2</span>,</span>
<span id="cb25-20"><a href="#cb25-20" aria-hidden="true" tabindex="-1"></a>        num_train_epochs<span class="op">=</span>epochs, weight_decay<span class="op">=</span>wd, report_to<span class="op">=</span><span class="st">'none'</span>)</span>
<span id="cb25-21"><a href="#cb25-21" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> Trainer(model, args, train_dataset<span class="op">=</span>dds[<span class="st">'train'</span>], eval_dataset<span class="op">=</span>dds[<span class="st">'test'</span>],</span>
<span id="cb25-22"><a href="#cb25-22" aria-hidden="true" tabindex="-1"></a>                   tokenizer<span class="op">=</span>tokz, compute_metrics<span class="op">=</span>compute_metrics)</span>
<span id="cb25-23"><a href="#cb25-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-24"><a href="#cb25-24" aria-hidden="true" tabindex="-1"></a>    </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Now I can just run some crazy experiemnts!</p>
<div id="5cbabafc-abb3-4e1c-94e6-2fa430d04a5e" class="cell" data-execution_count="17">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Testing the effect of switching the fill string</span></span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>na_fill <span class="op">=</span> <span class="st">'none'</span></span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>df[input_col] <span class="op">=</span> <span class="st">'LOC: '</span> <span class="op">+</span> df.location.fillna(na_fill) <span class="op">+</span> <span class="st">'; KW: '</span> <span class="op">+</span> df.keyword.fillna(na_fill) <span class="op">+</span> <span class="st">'; TEXT: '</span> <span class="op">+</span> df.text.fillna(na_fill)</span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(df.inputs.head())</span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a>dds <span class="op">=</span> get_dds(df)</span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a>get_trainer(dds).train()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>0                                                                    LOC: none; KW: none; TEXT: Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all
1                                                                                                   LOC: none; KW: none; TEXT: Forest fire near La Ronge Sask. Canada
2    LOC: none; KW: none; TEXT: All residents asked to 'shelter in place' are being notified by officers. No other evacuation or shelter in place orders are expected
3                                                                        LOC: none; KW: none; TEXT: 13,000 people receive #wildfires evacuation orders in California 
4                                                 LOC: none; KW: none; TEXT: Just got sent this photo from Ruby #Alaska as smoke from #wildfires pours into a school 
Name: inputs, dtype: object</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"8fd42ace8cf9476eb7e62b511ad69c1d","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Some weights of the model checkpoint at microsoft/deberta-v3-small were not used when initializing DebertaV2ForSequenceClassification: ['mask_predictions.LayerNorm.weight', 'mask_predictions.LayerNorm.bias', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.classifier.bias', 'mask_predictions.dense.bias', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.bias']
- This IS expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-small and are newly initialized: ['pooler.dense.weight', 'classifier.weight', 'pooler.dense.bias', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.</code></pre>
</div>
<div class="cell-output cell-output-display">

    <div>
      
      <progress value="180" max="180" style="width:300px; height:20px; vertical-align: middle;"></progress>
      [180/180 00:28, Epoch 4/4]
    </div>
    
<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">Epoch</th>
<th data-quarto-table-cell-role="th">Training Loss</th>
<th data-quarto-table-cell-role="th">Validation Loss</th>
<th data-quarto-table-cell-role="th">F1</th>
<th data-quarto-table-cell-role="th">Accuracy</th>
<th data-quarto-table-cell-role="th">Precision</th>
<th data-quarto-table-cell-role="th">Recall</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td>No log</td>
<td>0.435222</td>
<td>0.743494</td>
<td>0.818803</td>
<td>0.899281</td>
<td>0.633714</td>
</tr>
<tr class="even">
<td>2</td>
<td>No log</td>
<td>0.412216</td>
<td>0.797673</td>
<td>0.835609</td>
<td>0.813984</td>
<td>0.782003</td>
</tr>
<tr class="odd">
<td>3</td>
<td>No log</td>
<td>0.490506</td>
<td>0.782878</td>
<td>0.816176</td>
<td>0.766707</td>
<td>0.799747</td>
</tr>
<tr class="even">
<td>4</td>
<td>No log</td>
<td>0.489541</td>
<td>0.789371</td>
<td>0.829307</td>
<td>0.807692</td>
<td>0.771863</td>
</tr>
</tbody>
</table>
<p>
</p></div>
<div class="cell-output cell-output-display" data-execution_count="17">
<pre><code>TrainOutput(global_step=180, training_loss=0.35910987854003906, metrics={'train_runtime': 28.2531, 'train_samples_per_second': 808.264, 'train_steps_per_second': 6.371, 'total_flos': 464396789823708.0, 'train_loss': 0.35910987854003906, 'epoch': 4.0})</code></pre>
</div>
</div>
<p>Doesn’t seem to be a large effect. Does lowercasing the strings help?</p>
<div id="13941592-70b6-4569-8663-098b129471da" class="cell" data-execution_count="18">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a>na_fill <span class="op">=</span> <span class="st">''</span></span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>df[input_col] <span class="op">=</span> <span class="st">'LOC: '</span> <span class="op">+</span> df.location.fillna(na_fill) <span class="op">+</span> <span class="st">'; KW: '</span> <span class="op">+</span> df.keyword.fillna(na_fill) <span class="op">+</span> <span class="st">'; TEXT: '</span> <span class="op">+</span> df.text.fillna(na_fill)</span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a>df[input_col] <span class="op">=</span> df.inputs.<span class="bu">str</span>.lower()</span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a>dds <span class="op">=</span> get_dds(df)</span>
<span id="cb30-7"><a href="#cb30-7" aria-hidden="true" tabindex="-1"></a>get_trainer(dds).train()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"5948d4d57fdc4d058b3b91c457b2a893","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Some weights of the model checkpoint at microsoft/deberta-v3-small were not used when initializing DebertaV2ForSequenceClassification: ['mask_predictions.LayerNorm.weight', 'mask_predictions.LayerNorm.bias', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.classifier.bias', 'mask_predictions.dense.bias', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.bias']
- This IS expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-small and are newly initialized: ['pooler.dense.weight', 'classifier.weight', 'pooler.dense.bias', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.</code></pre>
</div>
<div class="cell-output cell-output-display">

    <div>
      
      <progress value="180" max="180" style="width:300px; height:20px; vertical-align: middle;"></progress>
      [180/180 00:27, Epoch 4/4]
    </div>
    
<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">Epoch</th>
<th data-quarto-table-cell-role="th">Training Loss</th>
<th data-quarto-table-cell-role="th">Validation Loss</th>
<th data-quarto-table-cell-role="th">F1</th>
<th data-quarto-table-cell-role="th">Accuracy</th>
<th data-quarto-table-cell-role="th">Precision</th>
<th data-quarto-table-cell-role="th">Recall</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td>No log</td>
<td>0.440292</td>
<td>0.733683</td>
<td>0.813550</td>
<td>0.898897</td>
<td>0.619772</td>
</tr>
<tr class="even">
<td>2</td>
<td>No log</td>
<td>0.412970</td>
<td>0.790576</td>
<td>0.831933</td>
<td>0.817321</td>
<td>0.765526</td>
</tr>
<tr class="odd">
<td>3</td>
<td>No log</td>
<td>0.454561</td>
<td>0.795322</td>
<td>0.834559</td>
<td>0.816000</td>
<td>0.775665</td>
</tr>
<tr class="even">
<td>4</td>
<td>No log</td>
<td>0.493377</td>
<td>0.793103</td>
<td>0.829832</td>
<td>0.799228</td>
<td>0.787072</td>
</tr>
</tbody>
</table>
<p>
</p></div>
<div class="cell-output cell-output-display" data-execution_count="18">
<pre><code>TrainOutput(global_step=180, training_loss=0.3674246470133464, metrics={'train_runtime': 27.6703, 'train_samples_per_second': 825.29, 'train_steps_per_second': 6.505, 'total_flos': 449771816332608.0, 'train_loss': 0.3674246470133464, 'epoch': 4.0})</code></pre>
</div>
</div>
<p>What about removing the “%20”s from the keywords?</p>
<div id="ecbdc1f7-6cd6-4553-87a5-cb5aada29f95" class="cell" data-execution_count="19">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a>na_fill <span class="op">=</span> <span class="st">''</span></span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>df[input_col] <span class="op">=</span> <span class="st">'LOC: '</span> <span class="op">+</span> df.location.fillna(na_fill) <span class="op">+</span> <span class="st">'; KW: '</span> <span class="op">+</span> df.keyword.fillna(na_fill).<span class="bu">str</span>.replace(<span class="st">"%20"</span>, <span class="st">' '</span>) <span class="op">+</span> <span class="st">'; TEXT: '</span> <span class="op">+</span> df.text.fillna(na_fill)</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a>dds <span class="op">=</span> get_dds(df)</span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a>get_trainer(dds).train()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"c82c1ffa24404edbaeece11506046e4e","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Some weights of the model checkpoint at microsoft/deberta-v3-small were not used when initializing DebertaV2ForSequenceClassification: ['mask_predictions.LayerNorm.weight', 'mask_predictions.LayerNorm.bias', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.classifier.bias', 'mask_predictions.dense.bias', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.bias']
- This IS expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-small and are newly initialized: ['pooler.dense.weight', 'classifier.weight', 'pooler.dense.bias', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.</code></pre>
</div>
<div class="cell-output cell-output-display">

    <div>
      
      <progress value="180" max="180" style="width:300px; height:20px; vertical-align: middle;"></progress>
      [180/180 00:28, Epoch 4/4]
    </div>
    
<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">Epoch</th>
<th data-quarto-table-cell-role="th">Training Loss</th>
<th data-quarto-table-cell-role="th">Validation Loss</th>
<th data-quarto-table-cell-role="th">F1</th>
<th data-quarto-table-cell-role="th">Accuracy</th>
<th data-quarto-table-cell-role="th">Precision</th>
<th data-quarto-table-cell-role="th">Recall</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td>No log</td>
<td>0.443140</td>
<td>0.737075</td>
<td>0.813025</td>
<td>0.883186</td>
<td>0.632446</td>
</tr>
<tr class="even">
<td>2</td>
<td>No log</td>
<td>0.403884</td>
<td>0.785333</td>
<td>0.830882</td>
<td>0.828411</td>
<td>0.746515</td>
</tr>
<tr class="odd">
<td>3</td>
<td>No log</td>
<td>0.468701</td>
<td>0.784762</td>
<td>0.821954</td>
<td>0.786260</td>
<td>0.783270</td>
</tr>
<tr class="even">
<td>4</td>
<td>No log</td>
<td>0.497474</td>
<td>0.789809</td>
<td>0.826681</td>
<td>0.793854</td>
<td>0.785805</td>
</tr>
</tbody>
</table>
<p>
</p></div>
<div class="cell-output cell-output-display" data-execution_count="19">
<pre><code>TrainOutput(global_step=180, training_loss=0.35947723388671876, metrics={'train_runtime': 28.3494, 'train_samples_per_second': 805.518, 'train_steps_per_second': 6.349, 'total_flos': 461217459009756.0, 'train_loss': 0.35947723388671876, 'epoch': 4.0})</code></pre>
</div>
</div>
<p>None of these transformations seem to be helping us become more accurate. There are several more experiments that we could run, but I had another idea that I wanted to try first…</p>
<section id="special-tokens" class="level2">
<h2 class="anchored" data-anchor-id="special-tokens">Special Tokens?</h2>
<p>I noticed that the high-confidence incorrect predictions above all had links. I wonder what ahppens if I make some subset of links, tags, and hashtags into special tokens. I think it makes more sense to do it with tags and links because the text of each of those doesn’t have much to do with the meaning of the data. The hashtag, however, does contain useful information. But I’ll run some experiments and see what happens.</p>
<div id="a3652aee-aeef-4232-981e-8b9da9433af0" class="cell" data-execution_count="20">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="co"># create new special tokens</span></span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a>new_toks <span class="op">=</span> [<span class="st">"[L]"</span>, <span class="st">"[A]"</span>, <span class="st">"[X]"</span>]</span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a>tokz.add_special_tokens({<span class="st">'additional_special_tokens'</span>: new_toks})</span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-5"><a href="#cb36-5" aria-hidden="true" tabindex="-1"></a><span class="co"># remove links and replace with [L]</span></span>
<span id="cb36-6"><a href="#cb36-6" aria-hidden="true" tabindex="-1"></a>df.loc[:, <span class="st">'mod_text'</span>] <span class="op">=</span> (</span>
<span id="cb36-7"><a href="#cb36-7" aria-hidden="true" tabindex="-1"></a>    df[<span class="st">'text'</span>]</span>
<span id="cb36-8"><a href="#cb36-8" aria-hidden="true" tabindex="-1"></a>    .astype(<span class="bu">str</span>) </span>
<span id="cb36-9"><a href="#cb36-9" aria-hidden="true" tabindex="-1"></a>    .<span class="bu">str</span>.replace(<span class="vs">r'https?://\S+'</span>, <span class="st">'[L]'</span>, regex<span class="op">=</span><span class="va">True</span>))   <span class="co"># Match http or https links</span></span>
<span id="cb36-10"><a href="#cb36-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-11"><a href="#cb36-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-12"><a href="#cb36-12" aria-hidden="true" tabindex="-1"></a>na_fill <span class="op">=</span> <span class="st">''</span></span>
<span id="cb36-13"><a href="#cb36-13" aria-hidden="true" tabindex="-1"></a>df[input_col] <span class="op">=</span> <span class="st">'LOC: '</span> <span class="op">+</span> df.location.fillna(na_fill) <span class="op">+</span> <span class="st">'; KW: '</span> <span class="op">+</span> df.keyword.fillna(na_fill) <span class="op">+</span> <span class="st">'; TEXT: '</span> <span class="op">+</span> df.mod_text.fillna(na_fill)</span>
<span id="cb36-14"><a href="#cb36-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-15"><a href="#cb36-15" aria-hidden="true" tabindex="-1"></a>dds <span class="op">=</span> get_dds(df)</span>
<span id="cb36-16"><a href="#cb36-16" aria-hidden="true" tabindex="-1"></a>get_trainer(dds, model).train()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"9ae2bff470d6437ba06ad168d07757a8","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">

    <div>
      
      <progress value="180" max="180" style="width:300px; height:20px; vertical-align: middle;"></progress>
      [180/180 00:24, Epoch 4/4]
    </div>
    
<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">Epoch</th>
<th data-quarto-table-cell-role="th">Training Loss</th>
<th data-quarto-table-cell-role="th">Validation Loss</th>
<th data-quarto-table-cell-role="th">F1</th>
<th data-quarto-table-cell-role="th">Accuracy</th>
<th data-quarto-table-cell-role="th">Precision</th>
<th data-quarto-table-cell-role="th">Recall</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td>No log</td>
<td>0.357041</td>
<td>0.801756</td>
<td>0.857668</td>
<td>0.948097</td>
<td>0.694550</td>
</tr>
<tr class="even">
<td>2</td>
<td>No log</td>
<td>0.344914</td>
<td>0.837116</td>
<td>0.871849</td>
<td>0.884344</td>
<td>0.794677</td>
</tr>
<tr class="odd">
<td>3</td>
<td>No log</td>
<td>0.431433</td>
<td>0.828608</td>
<td>0.860294</td>
<td>0.842726</td>
<td>0.814956</td>
</tr>
<tr class="even">
<td>4</td>
<td>No log</td>
<td>0.467705</td>
<td>0.826142</td>
<td>0.856092</td>
<td>0.827192</td>
<td>0.825095</td>
</tr>
</tbody>
</table>
<p>
</p></div>
<div class="cell-output cell-output-display" data-execution_count="20">
<pre><code>TrainOutput(global_step=180, training_loss=0.22589988708496095, metrics={'train_runtime': 24.4876, 'train_samples_per_second': 932.552, 'train_steps_per_second': 7.351, 'total_flos': 374670733971756.0, 'train_loss': 0.22589988708496095, 'epoch': 4.0})</code></pre>
</div>
</div>
<p>Awesome, huge jump! This makes sense because there’s no great way to tokenize links and get real meaning from them; the text of a shortened link doesn’t really tell much about whats in it.</p>
<div id="24b2280a-1753-4e6d-8bc4-b8394f405daa" class="cell" data-execution_count="21">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="co"># keep previous formatting and remove mentions replace with [A]</span></span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a>df.loc[:, <span class="st">'mod_text'</span>] <span class="op">=</span> (</span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a>    df[<span class="st">'text'</span>]</span>
<span id="cb38-4"><a href="#cb38-4" aria-hidden="true" tabindex="-1"></a>    .astype(<span class="bu">str</span>)</span>
<span id="cb38-5"><a href="#cb38-5" aria-hidden="true" tabindex="-1"></a>    .<span class="bu">str</span>.replace(<span class="vs">r'https?://\S+'</span>, <span class="st">'[L]'</span>, regex<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb38-6"><a href="#cb38-6" aria-hidden="true" tabindex="-1"></a>    .<span class="bu">str</span>.replace(<span class="vs">r'@\w+'</span>, <span class="st">'[A]'</span>, regex<span class="op">=</span><span class="va">True</span>))</span>
<span id="cb38-7"><a href="#cb38-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-8"><a href="#cb38-8" aria-hidden="true" tabindex="-1"></a>na_fill <span class="op">=</span> <span class="st">''</span></span>
<span id="cb38-9"><a href="#cb38-9" aria-hidden="true" tabindex="-1"></a>df[input_col] <span class="op">=</span> <span class="st">'LOC: '</span> <span class="op">+</span> df.location.fillna(na_fill) <span class="op">+</span> <span class="st">'; KW: '</span> <span class="op">+</span> df.keyword.fillna(na_fill) <span class="op">+</span> <span class="st">'; TEXT: '</span> <span class="op">+</span> df.mod_text.fillna(na_fill)</span>
<span id="cb38-10"><a href="#cb38-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-11"><a href="#cb38-11" aria-hidden="true" tabindex="-1"></a>dds <span class="op">=</span> get_dds(df)</span>
<span id="cb38-12"><a href="#cb38-12" aria-hidden="true" tabindex="-1"></a>get_trainer(dds, model).train()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"ce2b6f30c36847ca9fe454d70bcb753b","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">

    <div>
      
      <progress value="180" max="180" style="width:300px; height:20px; vertical-align: middle;"></progress>
      [180/180 00:23, Epoch 4/4]
    </div>
    
<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">Epoch</th>
<th data-quarto-table-cell-role="th">Training Loss</th>
<th data-quarto-table-cell-role="th">Validation Loss</th>
<th data-quarto-table-cell-role="th">F1</th>
<th data-quarto-table-cell-role="th">Accuracy</th>
<th data-quarto-table-cell-role="th">Precision</th>
<th data-quarto-table-cell-role="th">Recall</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td>No log</td>
<td>0.532192</td>
<td>0.827950</td>
<td>0.862920</td>
<td>0.862637</td>
<td>0.795944</td>
</tr>
<tr class="even">
<td>2</td>
<td>No log</td>
<td>0.574797</td>
<td>0.800705</td>
<td>0.821954</td>
<td>0.746711</td>
<td>0.863118</td>
</tr>
<tr class="odd">
<td>3</td>
<td>No log</td>
<td>0.538084</td>
<td>0.822023</td>
<td>0.853992</td>
<td>0.830530</td>
<td>0.813688</td>
</tr>
<tr class="even">
<td>4</td>
<td>No log</td>
<td>0.640214</td>
<td>0.824639</td>
<td>0.853466</td>
<td>0.817955</td>
<td>0.831432</td>
</tr>
</tbody>
</table>
<p>
</p></div>
<div class="cell-output cell-output-display" data-execution_count="21">
<pre><code>TrainOutput(global_step=180, training_loss=0.12367356618245443, metrics={'train_runtime': 23.7139, 'train_samples_per_second': 962.979, 'train_steps_per_second': 7.59, 'total_flos': 362423531491416.0, 'train_loss': 0.12367356618245443, 'epoch': 4.0})</code></pre>
</div>
</div>
<div id="c2af71b7-2c66-4bc7-8fae-418d820ec5bf" class="cell" data-execution_count="22">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="co"># keep previous formatting and remove hashtags replace with [X]</span></span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a>df.loc[:, <span class="st">'mod_text'</span>] <span class="op">=</span> (</span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a>    df[<span class="st">'text'</span>]</span>
<span id="cb40-4"><a href="#cb40-4" aria-hidden="true" tabindex="-1"></a>    .astype(<span class="bu">str</span>)</span>
<span id="cb40-5"><a href="#cb40-5" aria-hidden="true" tabindex="-1"></a>    .<span class="bu">str</span>.replace(<span class="vs">r'https?://\S+'</span>, <span class="st">'[L]'</span>, regex<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb40-6"><a href="#cb40-6" aria-hidden="true" tabindex="-1"></a>    .<span class="bu">str</span>.replace(<span class="vs">r'@\w+'</span>, <span class="st">'[A]'</span>, regex<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb40-7"><a href="#cb40-7" aria-hidden="true" tabindex="-1"></a>    .<span class="bu">str</span>.replace(<span class="vs">r'#\w+'</span>, <span class="st">'[X]'</span>, regex<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb40-8"><a href="#cb40-8" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb40-9"><a href="#cb40-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-10"><a href="#cb40-10" aria-hidden="true" tabindex="-1"></a>na_fill <span class="op">=</span> <span class="st">''</span></span>
<span id="cb40-11"><a href="#cb40-11" aria-hidden="true" tabindex="-1"></a>df[input_col] <span class="op">=</span> <span class="st">'LOC: '</span> <span class="op">+</span> df.location.fillna(na_fill) <span class="op">+</span> <span class="st">'; KW: '</span> <span class="op">+</span> df.keyword.fillna(na_fill) <span class="op">+</span> <span class="st">'; TEXT: '</span> <span class="op">+</span> df.mod_text.fillna(na_fill)</span>
<span id="cb40-12"><a href="#cb40-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-13"><a href="#cb40-13" aria-hidden="true" tabindex="-1"></a>dds <span class="op">=</span> get_dds(df)</span>
<span id="cb40-14"><a href="#cb40-14" aria-hidden="true" tabindex="-1"></a>get_trainer(dds, model).train()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"4900361347454fa9b331f4f457b1cc95","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">

    <div>
      
      <progress value="180" max="180" style="width:300px; height:20px; vertical-align: middle;"></progress>
      [180/180 00:23, Epoch 4/4]
    </div>
    
<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">Epoch</th>
<th data-quarto-table-cell-role="th">Training Loss</th>
<th data-quarto-table-cell-role="th">Validation Loss</th>
<th data-quarto-table-cell-role="th">F1</th>
<th data-quarto-table-cell-role="th">Accuracy</th>
<th data-quarto-table-cell-role="th">Precision</th>
<th data-quarto-table-cell-role="th">Recall</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td>No log</td>
<td>0.682632</td>
<td>0.799759</td>
<td>0.825630</td>
<td>0.762946</td>
<td>0.840304</td>
</tr>
<tr class="even">
<td>2</td>
<td>No log</td>
<td>0.551201</td>
<td>0.802696</td>
<td>0.830882</td>
<td>0.776987</td>
<td>0.830165</td>
</tr>
<tr class="odd">
<td>3</td>
<td>No log</td>
<td>0.612302</td>
<td>0.800490</td>
<td>0.828782</td>
<td>0.773964</td>
<td>0.828897</td>
</tr>
<tr class="even">
<td>4</td>
<td>No log</td>
<td>0.698242</td>
<td>0.804938</td>
<td>0.834034</td>
<td>0.784597</td>
<td>0.826362</td>
</tr>
</tbody>
</table>
<p>
</p></div>
<div class="cell-output cell-output-display" data-execution_count="22">
<pre><code>TrainOutput(global_step=180, training_loss=0.08939082887437609, metrics={'train_runtime': 23.3512, 'train_samples_per_second': 977.936, 'train_steps_per_second': 7.708, 'total_flos': 352560827121540.0, 'train_loss': 0.08939082887437609, 'epoch': 4.0})</code></pre>
</div>
</div>
<p>Ok, so as I predicted, the best combination is masking the links and mentions with a single new special token each. This makes sense because hashtags are often real words, whereas mentions are only rarely, and links never are. It’s all about tokenization. If there are pieces of data aren’t easy to tokenize, then the model spends resources attempting to do so. Or worse, it sees correlations where there aren’t any.</p>
</section>
</section>
<section id="submitting-results" class="level1">
<h1>Submitting Results</h1>
<p>I’m deciding to submit pretty early. I’m using what I know how to do so far and I want to see how far that takes me. I leave some examples of further analysis that I’d considr in order to make this a more competitive result.</p>
<div id="fe8424da-d841-4b7c-aa4b-d46437b041c8" class="cell" data-execution_count="24">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Rewrote dataframe transformation as a function</span></span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> transform_df(df_x):</span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a>    df_x.loc[:, <span class="st">'mod_text'</span>] <span class="op">=</span> (</span>
<span id="cb42-4"><a href="#cb42-4" aria-hidden="true" tabindex="-1"></a>        df_x[<span class="st">'text'</span>]</span>
<span id="cb42-5"><a href="#cb42-5" aria-hidden="true" tabindex="-1"></a>        .astype(<span class="bu">str</span>)</span>
<span id="cb42-6"><a href="#cb42-6" aria-hidden="true" tabindex="-1"></a>        .<span class="bu">str</span>.replace(<span class="vs">r'https?://\S+'</span>, <span class="st">'[L]'</span>, regex<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb42-7"><a href="#cb42-7" aria-hidden="true" tabindex="-1"></a>        .<span class="bu">str</span>.replace(<span class="vs">r'@\w+'</span>, <span class="st">'[A]'</span>, regex<span class="op">=</span><span class="va">True</span>))</span>
<span id="cb42-8"><a href="#cb42-8" aria-hidden="true" tabindex="-1"></a>    na_fill <span class="op">=</span> <span class="st">''</span></span>
<span id="cb42-9"><a href="#cb42-9" aria-hidden="true" tabindex="-1"></a>    df_x[input_col] <span class="op">=</span> <span class="st">'LOC: '</span> <span class="op">+</span> df_x.location.fillna(na_fill) <span class="op">+</span> <span class="st">'; KW: '</span> <span class="op">+</span> df_x.keyword.fillna(na_fill) <span class="op">+</span> <span class="st">'; TEXT: '</span> <span class="op">+</span> df_x.mod_text.fillna(na_fill)</span>
<span id="cb42-10"><a href="#cb42-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> df_x</span>
<span id="cb42-11"><a href="#cb42-11" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb42-12"><a href="#cb42-12" aria-hidden="true" tabindex="-1"></a>df_trans <span class="op">=</span> transform_df(df)</span>
<span id="cb42-13"><a href="#cb42-13" aria-hidden="true" tabindex="-1"></a>dds <span class="op">=</span> get_dds(df_trans)</span>
<span id="cb42-14"><a href="#cb42-14" aria-hidden="true" tabindex="-1"></a>trainer <span class="op">=</span> get_trainer(dds, model)</span>
<span id="cb42-15"><a href="#cb42-15" aria-hidden="true" tabindex="-1"></a>trainer.train()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"e1013d99b593442cb6042e61251784bd","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">

    <div>
      
      <progress value="180" max="180" style="width:300px; height:20px; vertical-align: middle;"></progress>
      [180/180 00:23, Epoch 4/4]
    </div>
    
<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">Epoch</th>
<th data-quarto-table-cell-role="th">Training Loss</th>
<th data-quarto-table-cell-role="th">Validation Loss</th>
<th data-quarto-table-cell-role="th">F1</th>
<th data-quarto-table-cell-role="th">Accuracy</th>
<th data-quarto-table-cell-role="th">Precision</th>
<th data-quarto-table-cell-role="th">Recall</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td>No log</td>
<td>0.948050</td>
<td>0.793727</td>
<td>0.820378</td>
<td>0.757192</td>
<td>0.833967</td>
</tr>
<tr class="even">
<td>2</td>
<td>No log</td>
<td>0.806260</td>
<td>0.805412</td>
<td>0.841387</td>
<td>0.819135</td>
<td>0.792142</td>
</tr>
<tr class="odd">
<td>3</td>
<td>No log</td>
<td>1.134959</td>
<td>0.780175</td>
<td>0.801996</td>
<td>0.722462</td>
<td>0.847909</td>
</tr>
<tr class="even">
<td>4</td>
<td>No log</td>
<td>0.833781</td>
<td>0.795699</td>
<td>0.830357</td>
<td>0.794192</td>
<td>0.797212</td>
</tr>
</tbody>
</table>
<p>
</p></div>
<div class="cell-output cell-output-display" data-execution_count="24">
<pre><code>TrainOutput(global_step=180, training_loss=0.035915311177571616, metrics={'train_runtime': 23.6941, 'train_samples_per_second': 963.784, 'train_steps_per_second': 7.597, 'total_flos': 362423531491416.0, 'train_loss': 0.035915311177571616, 'epoch': 4.0})</code></pre>
</div>
</div>
<p>I rewrote the transformation as a function so we can be sure we do exactly the same thing to our test dataset.</p>
<div id="dc8400c8-a26e-4069-a04a-cedc3980fb48" class="cell" data-execution_count="23">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a>df_test.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="23">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">id</th>
<th data-quarto-table-cell-role="th">keyword</th>
<th data-quarto-table-cell-role="th">location</th>
<th data-quarto-table-cell-role="th">text</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>0</td>
<td>NaN</td>
<td>NaN</td>
<td>Just happened a terrible car crash</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>2</td>
<td>NaN</td>
<td>NaN</td>
<td>Heard about #earthquake is different cities, stay safe everyone.</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>3</td>
<td>NaN</td>
<td>NaN</td>
<td>there is a forest fire at spot pond, geese are fleeing across the street, I cannot save them all</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>9</td>
<td>NaN</td>
<td>NaN</td>
<td>Apocalypse lighting. #Spokane #wildfires</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>11</td>
<td>NaN</td>
<td>NaN</td>
<td>Typhoon Soudelor kills 28 in China and Taiwan</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div id="3a422a80-7ec6-40b1-b868-f18fe64bf7de" class="cell" data-execution_count="26">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Transform test dataset based on work we just did</span></span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-3"><a href="#cb45-3" aria-hidden="true" tabindex="-1"></a>df_test_trans <span class="op">=</span> transform_df(df_test)</span>
<span id="cb45-4"><a href="#cb45-4" aria-hidden="true" tabindex="-1"></a>test_ds <span class="op">=</span> Dataset.from_pandas(df_test).<span class="bu">map</span>(tok_func, batched<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb45-5"><a href="#cb45-5" aria-hidden="true" tabindex="-1"></a>outputs <span class="op">=</span> trainer.predict(test_ds)</span>
<span id="cb45-6"><a href="#cb45-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="bu">len</span>(test_ds), <span class="bu">len</span>(df))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"a983005b3f774385b33bd96670e2035f","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">

</div>
<div class="cell-output cell-output-stdout">
<pre><code>3263 7613</code></pre>
</div>
</div>
<div id="5908b1e3-29b5-4f3b-a100-d1a726da24fb" class="cell" data-execution_count="27">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a>outputs <span class="op">=</span> trainer.predict(test_ds)</span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a>logits <span class="op">=</span> outputs.predictions</span>
<span id="cb47-3"><a href="#cb47-3" aria-hidden="true" tabindex="-1"></a>probs <span class="op">=</span> F.softmax(tensor(logits), dim<span class="op">=</span><span class="dv">1</span>).numpy()</span>
<span id="cb47-4"><a href="#cb47-4" aria-hidden="true" tabindex="-1"></a>preds <span class="op">=</span> probs.argmax(axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb47-5"><a href="#cb47-5" aria-hidden="true" tabindex="-1"></a>df_test_results <span class="op">=</span> pd.DataFrame({</span>
<span id="cb47-6"><a href="#cb47-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">"pred"</span>: preds,</span>
<span id="cb47-7"><a href="#cb47-7" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb47-8"><a href="#cb47-8" aria-hidden="true" tabindex="-1"></a>df_test.<span class="bu">id</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">

</div>
<div class="cell-output cell-output-display" data-execution_count="27">
<pre><code>0           0
1           2
2           3
3           9
4          11
        ...  
3258    10861
3259    10865
3260    10868
3261    10874
3262    10875
Name: id, Length: 3263, dtype: int64</code></pre>
</div>
</div>
<p>Now we can finally submit to kaggle.</p>
<div id="2d31381d-9aab-4b37-8413-4aae62ce6768" class="cell" data-execution_count="26">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb49"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> datasets</span>
<span id="cb49-2"><a href="#cb49-2" aria-hidden="true" tabindex="-1"></a>submission <span class="op">=</span> datasets.Dataset.from_dict({</span>
<span id="cb49-3"><a href="#cb49-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">'id'</span>: df_test[<span class="st">'id'</span>],</span>
<span id="cb49-4"><a href="#cb49-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">'target'</span>: df_test_results[<span class="st">"pred"</span>]</span>
<span id="cb49-5"><a href="#cb49-5" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb49-6"><a href="#cb49-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="bu">len</span>(df_test.<span class="bu">id</span>), <span class="bu">len</span>(df_test_results.pred))</span>
<span id="cb49-7"><a href="#cb49-7" aria-hidden="true" tabindex="-1"></a>submission.to_csv(<span class="st">'nlp_tweets_submission.csv'</span>, index<span class="op">=</span><span class="va">False</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>3263 3263</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"59227e87126a4ffabf32b1ad420e3c31","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display" data-execution_count="26">
<pre><code>22746</code></pre>
</div>
</div>
</section>
<section id="reflection" class="level1">
<h1>Reflection</h1>
<p>So, I performed right in the middle of the pack (rank 367/784). I was able to classify the tweets at a rate of <strong>.79895</strong>. This makes sense. I didn’t really do a mega-deep dive into the data. I mostly just wanted to get some predictions and submit them. If I have time I’ll go deeper into it, and see if I can get a higher score. Here’s what I would try:</p>
<ul>
<li>I would probably try to use a different model. We used deberta for prototyping, but if we used a stronger deberta or another model we’d likely do better. Maybe something specifically trained on tweets.</li>
<li>I would add sentiment analysis to see if I can use that feature to make a more robust validation set. We never quite found a feature of the data that was harder to classify, so we couldn’t make a meaningful validation set. I would want to do further research into this and see if a better validation set could be created.</li>
</ul>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/aaronjames95\.github\.io\/quarto_blog\/");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>